{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from enum import Enum \n",
    "from copy import copy\n",
    "\n",
    "import abc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1fb1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "# visualize plots in the jupyter notebook\n",
    "# check more https://goo.gl/U3Ai8R\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_function(V, title='Value Function', generate_gif=False, train_steps=None):\n",
    "    \"\"\"\n",
    "    Plots a value function as a surface plot, like in: https://goo.gl/aF2doj\n",
    "\n",
    "    You can choose between just plotting the graph for the value function\n",
    "    which is the default behaviour (generate_gif=False) or to train the agent\n",
    "    a couple of times and save the frames in a gif as you train.\n",
    "\n",
    "    Args:\n",
    "        agent: An agent.\n",
    "        title (string): Plot title.\n",
    "        generate_gif (boolean): If want to save plots as a gif.\n",
    "        train_steps: If is not None and generate_gif = True, then will use this\n",
    "                     value as the number of steps to train the model at each frame.\n",
    "    \"\"\"\n",
    "    # you can change this values to change the size of the graph\n",
    "    fig = plt.figure(title, figsize=(10, 5))\n",
    "    \n",
    "    # explanation about this line: https://goo.gl/LH5E7i\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    def plot_frame(ax):\n",
    "        # min value allowed accordingly with the documentation is 1\n",
    "        # we're getting the max value from V dimensions\n",
    "        min_x = 1\n",
    "        max_x = V.shape[0]\n",
    "        min_y = 1\n",
    "        max_y = V.shape[1]\n",
    "\n",
    "        # creates a sequence from min to max\n",
    "        x_range = np.arange(min_x, max_x)\n",
    "        y_range = np.arange(min_y, max_y)\n",
    "\n",
    "        # creates a grid representation of x_range and y_range\n",
    "        X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "        # get value function for X and Y values\n",
    "        def get_stat_val(x, y):\n",
    "            return V[x, y]\n",
    "        Z = get_stat_val(X, Y)\n",
    "\n",
    "        # creates a surface to be ploted\n",
    "        # check documentation for details: https://goo.gl/etEhPP\n",
    "        ax.set_xlabel('Dealer Showing')\n",
    "        ax.set_ylabel('Player Sum')\n",
    "        ax.set_zlabel('Value')\n",
    "        return ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm, \n",
    "                               linewidth=0, antialiased=False)\n",
    "\n",
    "    surf = plot_frame(ax)\n",
    "    plt.title(title)\n",
    "    fig.canvas.draw()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31796da",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7561f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    stick = 0\n",
    "    hit = 1\n",
    "    \n",
    "class Mode(Enum):\n",
    "    exploit = 0\n",
    "    explore = 1\n",
    "    \n",
    "class CardColor(Enum):\n",
    "    red = 0\n",
    "    black = 1\n",
    "\n",
    "@dataclass\n",
    "class Card:\n",
    "    value: int = field(default_factory=lambda: np.random.randint(1, 11))\n",
    "    color: str = field(default_factory=lambda: np.random.choice([CardColor.red, CardColor.black], p=[1/3, 2/3]))\n",
    "        \n",
    "    @property\n",
    "    def key(self):\n",
    "        return f\"{self.color}{self.value}\"\n",
    "        \n",
    "@dataclass\n",
    "class State:\n",
    "    dealer_first_card: Card = field(default_factory=lambda: Card(color=CardColor.black))\n",
    "    player_sum: int = field(default_factory=lambda: Card(color=CardColor.black).value)\n",
    "    terminal: bool = False\n",
    "        \n",
    "    @property\n",
    "    def key(self):\n",
    "        return f\"{self.dealer_first_card.value}-{self.player_sum}-{self.terminal}\"\n",
    "    \n",
    "\n",
    "class Policy:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def step(self, state: State) -> Action:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class DealerPolicy(Policy):\n",
    "    \n",
    "    def step(self, state: State, dealer_sum: int):\n",
    "        \n",
    "        if dealer_sum < 17:\n",
    "            return Action.hit\n",
    "        \n",
    "        return Action.stick\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.player_sum = 0\n",
    "        self.dealer_sum = 0\n",
    "    \n",
    "    def initialize_state(self):\n",
    "        self.state = State()\n",
    "        self.player_sum = self.state.player_sum\n",
    "        self.dealer_sum = self.state.dealer_first_card.value\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    def get_state(self, set_terminal=True):\n",
    "        state = copy(self.state)\n",
    "        state.terminal = set_terminal \n",
    "        return state\n",
    "    \n",
    "    @staticmethod\n",
    "    def _update_sum(value: int, card: Card) -> int:\n",
    "        if card.color is CardColor.black:\n",
    "            value += card.value\n",
    "        elif card.color is CardColor.red:\n",
    "            value -= card.value\n",
    "        else:\n",
    "            raise Exception(f\"Card color {card.color} not known\")\n",
    "\n",
    "        return value\n",
    "    \n",
    "    def update_player_sum(self, card: Card) -> None:\n",
    "        self.player_sum = self._update_sum(self.player_sum, card)\n",
    "        self.state.player_sum = self.player_sum\n",
    "    \n",
    "    def update_dealer_sum(self, card: Card) -> None:\n",
    "        self.dealer_sum = self._update_sum(self.dealer_sum, card)\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_bust(value: int):\n",
    "        if value > 21 or value < 1:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def dealer_is_bust(self) -> bool:\n",
    "        return self._is_bust(self.dealer_sum)\n",
    "    \n",
    "    def player_is_bust(self) -> bool:\n",
    "        return self._is_bust(self.player_sum)\n",
    "\n",
    "    def step(self, action: Action):\n",
    "\n",
    "        if action is Action.hit:\n",
    "            self.update_player_sum(Card())\n",
    "\n",
    "            if self.player_is_bust():\n",
    "\n",
    "                # Player loses: reward -1\n",
    "                return self.get_state(), -1\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Game continues: reward 0 (intermediate step)\n",
    "                return self.get_state(set_terminal=False), 0\n",
    "\n",
    "        # Player sticks, dealer (environment) policy runs\n",
    "        elif action is Action.stick:\n",
    "            \n",
    "            while dealer_policy.step(self.get_state(), self.dealer_sum) is Action.hit:\n",
    "                \n",
    "                self.update_dealer_sum(Card())\n",
    "\n",
    "                if self.dealer_is_bust():\n",
    "\n",
    "                    # Player wins: reward +1\n",
    "                    return self.get_state(), 1\n",
    "\n",
    "            # Dealer won't draw more cards - determine reward\n",
    "            r = np.sign(self.player_sum - self.dealer_sum)\n",
    "\n",
    "            return self.get_state(), r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5824f99a",
   "metadata": {},
   "source": [
    "## Monte-carlo control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6852fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateActionPair:\n",
    "    \n",
    "    def __init__(self, state: State, action: Action):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "    \n",
    "    @property\n",
    "    def key(self):\n",
    "        return f\"{self.state.key}-{self.action.name}\"\n",
    "    \n",
    "def gen_state_action_pairs(state: State):\n",
    "    return (StateActionPair(state, action) for action in Action)\n",
    "\n",
    "class Registry(abc.ABC):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.r = dict()\n",
    "    \n",
    "    def __call__(self, key):\n",
    "        return self.r.get(key, 0)\n",
    "\n",
    "class CountRegistry(Registry):\n",
    "    def increment(self, key):\n",
    "        current = self.r.get(key, 0)\n",
    "        self.r[key] = current + 1\n",
    "\n",
    "class ValueRegistry(Registry):\n",
    "    def store(self, key, value):\n",
    "        self.r[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22235d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episodes = 1000000\n",
    "\n",
    "Nzero=100\n",
    "\n",
    "Q = ValueRegistry()\n",
    "Ns = CountRegistry()\n",
    "Nsa = CountRegistry()\n",
    "\n",
    "rewards = []\n",
    "\n",
    "env = Environment()\n",
    "\n",
    "dealer_policy = DealerPolicy()\n",
    "\n",
    "for i in range(episodes):\n",
    "    \n",
    "    if i % (round(episodes / 20)) == 0:\n",
    "        print(f\"Episode: {i:>10}/{episodes} --- {i/episodes*100:>5.1f}%\")\n",
    "\n",
    "    # Reset states list\n",
    "    state_action_pairs = []\n",
    "    \n",
    "    s = env.initialize_state()\n",
    "\n",
    "    while not s.terminal:\n",
    "\n",
    "        # Randomly decide wether to exploit or explore\n",
    "        eps = Nzero / (Nzero + Ns(s.key))\n",
    "        mode = np.random.choice([Mode.exploit, Mode.explore], p=[1-eps, eps])\n",
    "\n",
    "        # Exploit: take best action given q\n",
    "        if mode is Mode.exploit:\n",
    "            \n",
    "            # Evaluate Q function for both state, action pairs\n",
    "            sa_stick, sa_hit = gen_state_action_pairs(s)\n",
    "            Q_stick, Q_hit = Q(sa_stick.key), Q(sa_hit.key)\n",
    "            \n",
    "            # Greedy policy: take the one with the highest q value, if draw then 50/50\n",
    "            if Q_stick > Q_hit:\n",
    "                a = Action.stick\n",
    "            elif Q_stick < Q_hit:\n",
    "                a = Action.hit\n",
    "            else:\n",
    "                a = np.random.choice([Action.hit, Action.stick])\n",
    "\n",
    "        # Explore: randomly decide between actions\n",
    "        elif mode is Mode.explore:\n",
    "            a = np.random.choice([Action.hit, Action.stick])\n",
    "                       \n",
    "        # Append state-action pair to list\n",
    "        sa_next = StateActionPair(s, a)\n",
    "        state_action_pairs.append(sa_next)\n",
    "            \n",
    "        # Take step\n",
    "        s, G = env.step(a)\n",
    "        rewards.append(G)\n",
    "    \n",
    "    # Episode has ended, perform optimization step using G\n",
    "    for sa in state_action_pairs:\n",
    "        \n",
    "        # Update counters\n",
    "        Ns.increment(sa.state.key)\n",
    "        Nsa.increment(sa.key)\n",
    "        \n",
    "        # Update Qsa\n",
    "        q_current = Q(sa.key)\n",
    "        q_new = q_current + 1 / Nsa(sa.key) * (G - q_current)\n",
    "        Q.store(sa.key, q_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df1e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"key\": Q.r.keys(), \"q\": Q.r.values()})\n",
    "df[[\"Dealer showing\", \"Player sum\", \"terminated\", \"action\"]] = df[\"key\"].str.split(\"-\", expand=True).iloc[:, :4]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef09420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['terminated'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7699aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['terminated'].astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6398ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_v = df[df['terminated']==False][[\"Dealer showing\", \"Player sum\", \"q\"]]\n",
    "df_v = df_v.groupby([\"Dealer showing\", \"Player sum\"]).mean()\n",
    "df_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ba6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = df_v.unstack(level=0)\n",
    "v = v.reset_index(drop=True)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value_function(v.values.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_columns = v.columns.to_list()\n",
    "\n",
    "x_linspace = np.array(list(zip(*v_columns))[1], dtype=int)\n",
    "y_linspace = v.index.to_numpy()\n",
    "\n",
    "x, y = np.meshgrid(x_linspace, y_linspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead30fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(x, y, v.values, \n",
    "                       cmap=cm.coolwarm,\n",
    "                       rstride=1, cstride=1,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "ax.set_xlabel(\"Dealer showing\")\n",
    "ax.set_ylabel(\"Player sum\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e651e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_linspace.shape, y_linspace.shape)\n",
    "x_linspace, y_linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54344d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(x_linspace, y_linspace)\n",
    "print(x.shape, y.shape, v.transpose().values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(x, y, v.transpose().values, \n",
    "                       cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596434b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
